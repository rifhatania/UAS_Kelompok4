{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rifhatania/UAS_Kelompok4/blob/main/UAS_Kelompok4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "CuLsFDpuTCIN"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
        "from scipy.sparse import csr_matrix, issparse\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Input Dataset\n",
        "## a. Books Dataset\n",
        "print('Books Dataset')\n",
        "books = pd.read_csv('Books.csv', low_memory=False)\n",
        "print(\"Books:\", books.shape)\n",
        "print(books.head())\n",
        "\n",
        "## b. Users Dataset\n",
        "print('\\nUsers Dataset')\n",
        "users = pd.read_csv('Users.csv')\n",
        "print(\"Users:\", users.shape)\n",
        "print(users.head())\n",
        "\n",
        "## c. Books-Ratings Dataset\n",
        "print('\\nBooks-Ratings Dataset')\n",
        "ratings = pd.read_csv('Books-Ratings.csv')\n",
        "print(\"Ratings:\", ratings.shape)\n",
        "print(ratings)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-abZc0qNUzYq",
        "outputId": "6c5df220-85de-4b6e-8e40-b14d1e9e6c7d",
        "collapsed": true
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Books Dataset\n",
            "Books: (271360, 8)\n",
            "         ISBN                                         Book-Title  \\\n",
            "0  0195153448                                Classical Mythology   \n",
            "1  0002005018                                       Clara Callan   \n",
            "2  0060973129                               Decision in Normandy   \n",
            "3  0374157065  Flu: The Story of the Great Influenza Pandemic...   \n",
            "4  0393045218                             The Mummies of Urumchi   \n",
            "\n",
            "            Book-Author Year-Of-Publication                   Publisher  \\\n",
            "0    Mark P. O. Morford                2002     Oxford University Press   \n",
            "1  Richard Bruce Wright                2001       HarperFlamingo Canada   \n",
            "2          Carlo D'Este                1991             HarperPerennial   \n",
            "3      Gina Bari Kolata                1999        Farrar Straus Giroux   \n",
            "4       E. J. W. Barber                1999  W. W. Norton &amp; Company   \n",
            "\n",
            "                                         Image-URL-S  \\\n",
            "0  http://images.amazon.com/images/P/0195153448.0...   \n",
            "1  http://images.amazon.com/images/P/0002005018.0...   \n",
            "2  http://images.amazon.com/images/P/0060973129.0...   \n",
            "3  http://images.amazon.com/images/P/0374157065.0...   \n",
            "4  http://images.amazon.com/images/P/0393045218.0...   \n",
            "\n",
            "                                         Image-URL-M  \\\n",
            "0  http://images.amazon.com/images/P/0195153448.0...   \n",
            "1  http://images.amazon.com/images/P/0002005018.0...   \n",
            "2  http://images.amazon.com/images/P/0060973129.0...   \n",
            "3  http://images.amazon.com/images/P/0374157065.0...   \n",
            "4  http://images.amazon.com/images/P/0393045218.0...   \n",
            "\n",
            "                                         Image-URL-L  \n",
            "0  http://images.amazon.com/images/P/0195153448.0...  \n",
            "1  http://images.amazon.com/images/P/0002005018.0...  \n",
            "2  http://images.amazon.com/images/P/0060973129.0...  \n",
            "3  http://images.amazon.com/images/P/0374157065.0...  \n",
            "4  http://images.amazon.com/images/P/0393045218.0...  \n",
            "\n",
            "Users Dataset\n",
            "Users: (278858, 3)\n",
            "   User-ID                            Location   Age\n",
            "0        1                  nyc, new york, usa   NaN\n",
            "1        2           stockton, california, usa  18.0\n",
            "2        3     moscow, yukon territory, russia   NaN\n",
            "3        4           porto, v.n.gaia, portugal  17.0\n",
            "4        5  farnborough, hants, united kingdom   NaN\n",
            "\n",
            "Books-Ratings Dataset\n",
            "Ratings: (1149780, 3)\n",
            "         User-ID         ISBN  Book-Rating\n",
            "0         276725   034545104X            0\n",
            "1         276726   0155061224            5\n",
            "2         276727   0446520802            0\n",
            "3         276729   052165615X            3\n",
            "4         276729   0521795028            6\n",
            "...          ...          ...          ...\n",
            "1149775   276704   1563526298            9\n",
            "1149776   276706   0679447156            0\n",
            "1149777   276709   0515107662           10\n",
            "1149778   276721   0590442449           10\n",
            "1149779   276723  05162443314            8\n",
            "\n",
            "[1149780 rows x 3 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === 1. Cek Missing Value & Outlier ===\n",
        "print(\"=== Missing Value pada Books ===\")\n",
        "print(books[['Book-Title', 'Book-Author', 'Publisher']].isnull().sum())\n",
        "\n",
        "# Hapus kolom gambar yang tidak digunakan\n",
        "books.drop(columns=['Image-URL-S', 'Image-URL-M', 'Image-URL-L'], inplace=True)\n",
        "\n",
        "# Hapus baris buku dengan informasi penting yang kosong\n",
        "books.dropna(subset=['Book-Title', 'Book-Author', 'Publisher'], inplace=True)\n",
        "\n",
        "# Bersihkan umur users\n",
        "users['Age'] = pd.to_numeric(users['Age'], errors='coerce')\n",
        "users['Age'] = users['Age'].apply(lambda x: np.nan if x < 5 or x > 100 else x)\n",
        "print(\"\\nJumlah NULL kolom 'Age' setelah dibersihkan:\", users['Age'].isna().sum())\n",
        "\n",
        "# Bersihkan ratings: hanya ambil rating > 0\n",
        "ratings = ratings[ratings['Book-Rating'] > 0]\n",
        "print(\"\\nJumlah rating setelah buang rating 0:\", ratings.shape[0])\n",
        "\n",
        "# === 2. Merge ===\n",
        "# Merge ratings dengan users (biar ada info user kayak Age)\n",
        "ratings_users = pd.merge(ratings, users, on='User-ID', how='inner')\n",
        "\n",
        "# Merge ratings+users dengan books\n",
        "ratings_full = pd.merge(ratings_users, books, on='ISBN', how='inner')\n",
        "\n",
        "print(\"\\nKolom hasil merge:\")\n",
        "print(ratings_full.columns)\n",
        "\n",
        "# === 3. Encoding ===\n",
        "le_author = LabelEncoder()\n",
        "le_publisher = LabelEncoder()\n",
        "ratings_full['Author_Encoded'] = le_author.fit_transform(ratings_full['Book-Author'].astype(str))\n",
        "ratings_full['Publisher_Encoded'] = le_publisher.fit_transform(ratings_full['Publisher'].astype(str))\n",
        "\n",
        "print(\"\\nContoh hasil encoding:\")\n",
        "print(ratings_full[['Book-Author', 'Author_Encoded', 'Publisher', 'Publisher_Encoded']].head())\n",
        "\n",
        "# === 4. Normalisasi ===\n",
        "ratings_full['Year-Of-Publication'] = pd.to_numeric(ratings_full['Year-Of-Publication'], errors='coerce')\n",
        "ratings_full['Year-Of-Publication'].fillna(ratings_full['Year-Of-Publication'].median(), inplace=True)\n",
        "\n",
        "# Hitung rata-rata rating per ISBN â†’ lalu merge ke data\n",
        "avg_rating = ratings_full.groupby('ISBN')['Book-Rating'].mean().reset_index()\n",
        "avg_rating.columns = ['ISBN', 'AvgRating']\n",
        "ratings_full = pd.merge(ratings_full, avg_rating, on='ISBN', how='left')\n",
        "\n",
        "ratings_full['AvgRating'] = ratings_full['AvgRating'].fillna(0)\n",
        "\n",
        "# Normalisasi numerik\n",
        "scaler = MinMaxScaler()\n",
        "ratings_full[['Year_norm', 'AvgRating_norm']] = scaler.fit_transform(\n",
        "    ratings_full[['Year-Of-Publication', 'AvgRating']]\n",
        ")\n",
        "\n",
        "# === 5. Final Fitur Gabungan untuk Content-Based Filtering ===\n",
        "book_features = ratings_full[['ISBN', 'Book-Title', 'Year_norm', 'AvgRating_norm', 'Author_Encoded', 'Publisher_Encoded']].drop_duplicates()\n",
        "\n",
        "print(\"\\n=== Contoh Gabungan Fitur Buku ===\")\n",
        "print(book_features.head(10))\n",
        "\n",
        "# Simpan juga data yang masih punya User-ID untuk evaluasi\n",
        "ratings_with_features = pd.merge(ratings, book_features, on='ISBN', how='inner')\n",
        "\n",
        "print(\"\\nCek kolom final:\")\n",
        "print(ratings_with_features[['User-ID', 'ISBN', 'Book-Rating', 'Book-Title']].head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mVjSj7wBU5HL",
        "outputId": "e8bf6184-74ce-4d0b-c9ff-db961d4db79c",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Missing Value pada Books ===\n",
            "Book-Title     0\n",
            "Book-Author    2\n",
            "Publisher      2\n",
            "dtype: int64\n",
            "\n",
            "Jumlah NULL kolom 'Age' setelah dibersihkan: 112010\n",
            "\n",
            "Jumlah rating setelah buang rating 0: 433671\n",
            "\n",
            "Kolom hasil merge:\n",
            "Index(['User-ID', 'ISBN', 'Book-Rating', 'Location', 'Age', 'Book-Title',\n",
            "       'Book-Author', 'Year-Of-Publication', 'Publisher'],\n",
            "      dtype='object')\n",
            "\n",
            "Contoh hasil encoding:\n",
            "     Book-Author  Author_Encoded                   Publisher  \\\n",
            "0     Judith Rae           31469                      Heinle   \n",
            "1  Philip Prowse           47691  Cambridge University Press   \n",
            "2    Sue Leather           56130  Cambridge University Press   \n",
            "3   JOHN GRISHAM           24910                   Doubleday   \n",
            "4  Rebecca Wells           49197                 HarperTorch   \n",
            "\n",
            "   Publisher_Encoded  \n",
            "0               4755  \n",
            "1               1791  \n",
            "2               1791  \n",
            "3               2934  \n",
            "4               4607  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-18-326456700>:41: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  ratings_full['Year-Of-Publication'].fillna(ratings_full['Year-Of-Publication'].median(), inplace=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Contoh Gabungan Fitur Buku ===\n",
            "         ISBN                                         Book-Title  Year_norm  \\\n",
            "0  0155061224                                   Rites of Passage   0.976098   \n",
            "1  052165615X                                     Help!: Level 1   0.975122   \n",
            "2  0521795028  The Amsterdam Connection : Level 4 (Cambridge ...   0.976098   \n",
            "3  038550120X                                    A Painted House   0.976098   \n",
            "4  0060517794                           Little Altars Everywhere   0.977073   \n",
            "5  0671537458                                  Waiting to Exhale   0.973171   \n",
            "6  0679776818                  Birdsong: A Novel of Love and War   0.974146   \n",
            "7  0943066433                  How to Deal With Difficult People   0.973171   \n",
            "8  1885408226                      The Golden Rule of Schmoozing   0.974634   \n",
            "9  0747558167        Apricots on the Nile: A Memoir with Recipes   0.976585   \n",
            "\n",
            "   AvgRating_norm  Author_Encoded  Publisher_Encoded  \n",
            "0        0.444444           31469               4755  \n",
            "1        0.222222           47691               1791  \n",
            "2        0.555556           56130               1791  \n",
            "3        0.731139           24910               2934  \n",
            "4        0.777778           49197               4607  \n",
            "5        0.686275           57617               8085  \n",
            "6        0.719577           53855              10834  \n",
            "7        0.666667           50140               1860  \n",
            "8        0.666667            4176               6031  \n",
            "9        0.722222           10412               1381  \n",
            "\n",
            "Cek kolom final:\n",
            "   User-ID        ISBN  Book-Rating  \\\n",
            "0   276726  0155061224            5   \n",
            "1   276729  052165615X            3   \n",
            "2   276729  0521795028            6   \n",
            "3   276744  038550120X            7   \n",
            "4   276747  0060517794            9   \n",
            "\n",
            "                                          Book-Title  \n",
            "0                                   Rites of Passage  \n",
            "1                                     Help!: Level 1  \n",
            "2  The Amsterdam Connection : Level 4 (Cambridge ...  \n",
            "3                                    A Painted House  \n",
            "4                           Little Altars Everywhere  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === FILTER DATA UNTUK EFISIENSI ===\n",
        "# Ambil user yang kasih rating minimal 10 buku\n",
        "user_rating_count = ratings['User-ID'].value_counts()\n",
        "active_users = user_rating_count[user_rating_count >= 1].index\n",
        "ratings_filtered = ratings[ratings['User-ID'].isin(active_users)]\n",
        "\n",
        "# Ambil buku yang dirating minimal 50 user\n",
        "book_rating_count = ratings_filtered['ISBN'].value_counts()\n",
        "popular_books = book_rating_count[book_rating_count >= 100].index\n",
        "ratings_filtered = ratings_filtered[ratings_filtered['ISBN'].isin(popular_books)]\n",
        "\n",
        "print(\"Jumlah data setelah filter:\", ratings_filtered.shape)\n",
        "\n",
        "# === MATRIX RATING USER x ITEM ===\n",
        "rating_matrix = ratings_filtered.pivot_table(index='User-ID', columns='ISBN', values='Book-Rating').fillna(0)\n",
        "\n",
        "# Konversi ke sparse matrix\n",
        "from scipy.sparse import csr_matrix\n",
        "rating_sparse = csr_matrix(rating_matrix.values)\n",
        "\n",
        "# === 3a. Euclidean Similarity antar user ===\n",
        "from sklearn.metrics.pairwise import euclidean_distances\n",
        "euclidean_sim = euclidean_distances(rating_sparse)\n",
        "\n",
        "# === 3b. Cosine Similarity antar user ===\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "cosine_sim = cosine_similarity(rating_sparse)\n",
        "\n",
        "# === 3c. Pearson Correlation antar item ===\n",
        "pearson_sim = rating_matrix.T.corr(method='pearson', min_periods=10)\n",
        "\n",
        "print(\"\\nSimilarity calculation selesai.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hierqw4awsE-",
        "outputId": "a9dcfebf-ea7c-4146-c026-ab5c057c98ef",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Jumlah data setelah filter: (23501, 3)\n",
            "\n",
            "Similarity calculation selesai.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === PERBAIKI BOOK FEATURES AGAR LEBIH RINGAN ===\n",
        "# Filter book_features hanya yang masuk popular_books\n",
        "book_features_filtered = book_features[book_features['ISBN'].isin(popular_books)].reset_index(drop=True)\n",
        "\n",
        "# Ambil hanya fitur numerik dari book_features_filtered\n",
        "book_numerical_features = book_features_filtered[['Year_norm', 'AvgRating_norm', 'Author_Encoded', 'Publisher_Encoded']]\n",
        "\n",
        "# Hitung cosine similarity antar buku (Content-Based Filtering)\n",
        "book_content_sim = cosine_similarity(book_numerical_features.values)\n",
        "\n",
        "# Contoh: rekomendasikan buku mirip dengan buku ke-0\n",
        "idx_target = 0  # index buku yang ingin dicari rekomendasinya\n",
        "target_title = book_features_filtered.iloc[idx_target]['Book-Title']\n",
        "\n",
        "# Ambil indeks buku dengan similarity tertinggi (kecuali dirinya sendiri)\n",
        "similar_books_idx = book_content_sim[idx_target].argsort()[::-1][1:6]\n",
        "\n",
        "# Tampilkan hasil rekomendasi\n",
        "print(f\"\\nRekomendasi untuk buku: {target_title}\")\n",
        "for idx in similar_books_idx:\n",
        "    print(\"-\", book_features_filtered.iloc[idx]['Book-Title'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hCsH8hmIxMO4",
        "outputId": "84ea8092-ff98-4af3-8f4a-e65de3cce634",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Rekomendasi untuk buku: Harry Potter and the Order of the Phoenix (Book 5)\n",
            "- Harry Potter and the Prisoner of Azkaban (Book 3)\n",
            "- Harry Potter and the Prisoner of Azkaban (Book 3)\n",
            "- Harry Potter and the Sorcerer's Stone (Book 1)\n",
            "- Harry Potter and the Chamber of Secrets (Book 2)\n",
            "- Harry Potter and the Goblet of Fire (Book 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "# Ambil 20 user aktif secara acak\n",
        "sample_users = random.sample(list(ratings_filtered['User-ID'].unique()), 20)\n",
        "\n",
        "# Evaluasi: hitung berapa user yang mendapat rekomendasi yang 'benar'\n",
        "benar_count = 0\n",
        "\n",
        "for user_id in sample_users:\n",
        "    # Ambil buku dengan rating tinggi dari user ini\n",
        "    user_data = ratings_filtered[ratings_filtered['User-ID'] == user_id]\n",
        "    user_high_rated = user_data[user_data['Book-Rating'] >= 8]\n",
        "\n",
        "    if user_high_rated.empty:\n",
        "        continue  # skip user yang tidak punya rating tinggi\n",
        "\n",
        "    # Ambil 1 buku favorit dari user\n",
        "    user_fav_book = user_high_rated.sample(1, random_state=42).iloc[0]\n",
        "    isbn_fav = user_fav_book['ISBN']\n",
        "\n",
        "    # Cari indeks buku ini di book_features_filtered\n",
        "    try:\n",
        "        target_idx = book_features_filtered[book_features_filtered['ISBN'] == isbn_fav].index[0]\n",
        "    except IndexError:\n",
        "        continue  # buku tidak ditemukan dalam fitur, skip\n",
        "\n",
        "    # Cari rekomendasi dari buku favorit user\n",
        "    similar_idx = book_content_sim[target_idx].argsort()[::-1][1:6]\n",
        "    recommended_isbns = book_features_filtered.iloc[similar_idx]['ISBN'].values\n",
        "\n",
        "    # Cek apakah user pernah kasih rating tinggi ke salah satu rekomendasi\n",
        "    user_read_isbns = user_data[user_data['Book-Rating'] >= 8]['ISBN'].values\n",
        "\n",
        "    if any(isbn in user_read_isbns for isbn in recommended_isbns):\n",
        "        benar_count += 1\n",
        "\n",
        "# Hasil evaluasi\n",
        "print(f\"\\nEvaluasi Akhir:\")\n",
        "print(f\"Jumlah user yang dapat rekomendasi benar dari 20: {benar_count}/20\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L6HIeGaezb23",
        "outputId": "ee1e6a7f-a3e8-4c28-e469-e2cd52b0304a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluasi Akhir:\n",
            "Jumlah user yang dapat rekomendasi benar dari 20: 1/20\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Similarity\n",
        "\n",
        "# Merge data\n",
        "data = ratings.merge(books_filtered, on='ISBN').merge(users_filtered, on='User-ID')\n",
        "\n",
        "# --- Add Filtering to reduce pivot table size ---\n",
        "# Count how many ratings each user and book have\n",
        "user_counts = data['User-ID'].value_counts()\n",
        "book_counts = data['Book-Title'].value_counts()\n",
        "\n",
        "# Define thresholds (adjust these based on your RAM and dataset analysis)\n",
        "# For example, keep users who rated at least 10 books and books rated by at least 5 users\n",
        "user_threshold = 10\n",
        "book_threshold = 5\n",
        "\n",
        "# Get lists of users and books that meet the criteria\n",
        "users_to_keep = user_counts[user_counts >= user_threshold].index\n",
        "books_to_keep = book_counts[book_counts >= book_threshold].index\n",
        "\n",
        "# Filter the merged data\n",
        "filtered_data = data[data['User-ID'].isin(users_to_keep) & data['Book-Title'].isin(books_to_keep)]\n",
        "\n",
        "print(f\"\\nOriginal data shape: {data.shape}\")\n",
        "print(f\"Filtered data shape: {filtered_data.shape}\")\n",
        "\n",
        "# Create the user-item pivot table from the filtered data\n",
        "# This is the step that was likely causing high RAM usage\n",
        "# Using filtered_data instead of the full 'data'\n",
        "user_item = filtered_data.pivot_table(index='User-ID', columns='Book-Title', values='Book-Rating').fillna(0)\n",
        "\n",
        "print(f\"\\nUser-Item matrix shape: {user_item.shape}\")\n",
        "print(f\"Memory usage of user_item (MB): {user_item.memory_usage(deep=True).sum() / (1024**2):.2f}\")\n",
        "\n",
        "\n",
        "## a. Euclidean\n",
        "# Check if user_item is not empty before calculating similarity\n",
        "if not user_item.empty:\n",
        "    euclidean_sim = 1 / (1 + euclidean_distances(user_item))\n",
        "    euclidean_sim_df = pd.DataFrame(euclidean_sim, index=user_item.index, columns=user_item.index)\n",
        "    print(\"\\nEuclidean Similarity Matrix calculated.\")\n",
        "else:\n",
        "    print(\"\\nUser-Item matrix is empty after filtering, skipping Euclidean Similarity.\")\n",
        "\n",
        "\n",
        "## b. Consine Similarity\n",
        "if not user_item.empty:\n",
        "    cosine_sim = cosine_similarity(user_item)\n",
        "    cosine_sim_df = pd.DataFrame(cosine_sim, index=user_item.index, columns=user_item.index)\n",
        "    print(\"Cosine Similarity Matrix calculated.\")\n",
        "else:\n",
        "     print(\"User-Item matrix is empty after filtering, skipping Cosine Similarity.\")\n",
        "\n",
        "\n",
        "## c. Metode Lain: Pearson Correlation\n",
        "if not user_item.empty:\n",
        "    # Pearson correlation works on the transpose of the user-item matrix\n",
        "    # if calculating similarity between users based on item ratings.\n",
        "    # If calculating item similarity, you'd use user_item.corr()\n",
        "    # Assuming you want user similarity based on ratings:\n",
        "    pearson_sim = user_item.T.corr(method='pearson')\n",
        "    print(\"Pearson Correlation Matrix calculated.\")\n",
        "    print(pearson_sim)\n",
        "else:\n",
        "    print(\"User-Item matrix is empty after filtering, skipping Pearson Correlation.\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4d-YtiXGU8aK",
        "outputId": "60926091-8bcf-4752-9979-e3f244ee6c59"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Original data shape: (1031134, 6)\n",
            "Filtered data shape: (592850, 6)\n",
            "\n",
            "User-Item matrix shape: (11710, 39181)\n",
            "Memory usage of user_item (MB): 3500.53\n",
            "\n",
            "Euclidean Similarity Matrix calculated.\n",
            "Cosine Similarity Matrix calculated.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Content Based Filtering"
      ],
      "metadata": {
        "id": "BBmLmGGpVFRw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. Evaluasi"
      ],
      "metadata": {
        "id": "mwLxNJkpVJal"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity, euclidean_distances\n",
        "\n",
        "# Ambil fitur numerik saja\n",
        "numeric_features = book_features[['Year_norm', 'AvgRating_norm', 'Author_Encoded', 'Publisher_Encoded']]\n",
        "\n",
        "# Cosine Similarity\n",
        "cos_sim = cosine_similarity(numeric_features)\n",
        "\n",
        "# Euclidean Distance\n",
        "euc_dist = euclidean_distances(numeric_features)\n",
        "\n",
        "print(\"\\n=== Ukuran Matriks Similarity ===\")\n",
        "print(\"Cosine:\", cos_sim.shape)\n",
        "print(\"Euclidean:\", euc_dist.shape)"
      ],
      "metadata": {
        "id": "TLEXuk0ixdYM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}